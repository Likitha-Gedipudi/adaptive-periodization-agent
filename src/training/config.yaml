data:
  n_days: 180
  n_users: 200
  synthetic: true
  test_ratio: 0.15
  train_ratio: 0.7
  val_ratio: 0.15
early_stopping:
  enabled: false
  min_delta: 0.01
  monitor: mean_reward
  patience: 50
environment:
  apply_constraints: true
  episode_length: 90
  state_features: null
evaluation:
  compare_baselines: true
  deterministic: false
  n_episodes: 10
experiment:
  device: auto
  log_to_tensorboard: true
  log_to_wandb: false
  name: null
  output_dir: ./experiments
  seed: 42
  wandb_project: adaptive-periodization
reward:
  long_weight: 0.2
  medium_weight: 0.3
  penalty_weight: 0.3
  short_weight: 0.5
sac:
  alpha: 0.2
  auto_alpha: true
  batch_size: 256
  buffer_size: 100000
  gamma: 0.99
  hidden_dims:
  - 256
  - 128
  - 64
  learning_rate_actor: 0.0003
  learning_rate_critic: 0.0003
  tau: 0.005
training:
  checkpoint_frequency: 100
  episodes: 500
  eval_frequency: 50
  gradient_steps: 1
  log_frequency: 25
  steps_per_episode: 90
  warmup_steps: 1000
